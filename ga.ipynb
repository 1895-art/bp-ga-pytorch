{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "0b69742d-c976-4b7d-b82c-e7a213bfcb73",
   "display_name": "'Python Interactive'"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loader(x, y, batch_size=64):\n",
    "    data_size = x.shape[0]\n",
    "    permutation = np.random.permutation(data_size)\n",
    "    for i in range(0, data_size, batch_size):\n",
    "        batch_permutation = permutation[i: i+batch_size]\n",
    "        yield x[batch_permutation], y[batch_permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model, x_tensor):\n",
    "    x_axis = np.linspace(*X_BOUND, 200)\n",
    "    plt.plot(x_axis, F(x_axis))\n",
    "    plt.scatter(x_origin, np.squeeze(model(x_tensor).cpu().detach().numpy(), -1), color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x_tensor, y_tensor, num_epoches=10000, batch_size=4096, learning_rate=1e-3):\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_recorder = []\n",
    "    for e in range(num_epoches):\n",
    "        loss_recorder.clear()\n",
    "        for i, (x_batch, y_batch) in enumerate(batch_loader(x_tensor, y_tensor, batch_size=batch_size)):\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_recorder.append(loss.item())\n",
    "            print('batch {} loss {}'.format(\n",
    "                i+1, loss.item()\n",
    "            ), end='\\r')\n",
    "        # print('epoch {} loss {}'.format(\n",
    "        #     e+1, np.mean(loss_recorder)\n",
    "        # ))\n",
    "    return np.mean(loss_recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_model(model):\n",
    "    for layer in model:\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BOUND = [-10, 10]\n",
    "def F(x):\n",
    "    return x + 10*np.sin(5*x) + 7*np.cos(4*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "noise = 0.1\n",
    "x_origin = (X_BOUND[0] + (X_BOUND[1]-X_BOUND[0]) * np.random.rand(data_size))\n",
    "y_origin = F(x_origin) + noise * np.random.rand(data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "x_tensor = torch.from_numpy(x_origin).unsqueeze_(-1).float().to(device)\n",
    "y_tensor = torch.from_numpy(y_origin).unsqueeze_(-1).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 1),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "train(model, x_tensor, y_tensor, num_epoches=1000, batch_size=4096)\n",
    "plot_model(model, x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.state_dict()\n",
    "for key in params:\n",
    "    params[key] += torch.randn_like(params[key])\n",
    "model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 遗传算法"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遗传算法参数初始化\n",
    "maxgen = 1000                         # 进化代数，即迭代次数\n",
    "pop_size = 100                       # 种群规模\n",
    "pcross = 0.3                        # 交叉概率选择，0和1之间\n",
    "pmutation = 0.1                     # 变异概率选择，0和1之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def params_to_chrom(params):\n",
    "    chrom = np.empty(0)\n",
    "    for key in params:\n",
    "        chrom = np.append(chrom, params[key].cpu().numpy().flatten(), axis=-1)\n",
    "    return chrom\n",
    "\n",
    "def chrom_to_params(chrom, params_template):\n",
    "    params = copy.deepcopy(params_template)\n",
    "    idx = 0\n",
    "    for key in params:\n",
    "        param_length = np.prod(params_template[key].shape)\n",
    "        param = torch.from_numpy(chrom[idx: idx+param_length].reshape(params_template[key].shape)).to(device)\n",
    "        params[key] = param\n",
    "        idx += param_length\n",
    "    return params\n",
    "\n",
    "params = model.state_dict()\n",
    "params_ori = params\n",
    "params_template = copy.deepcopy(params)\n",
    "chrom = params_to_chrom(params)\n",
    "print(chrom.shape)\n",
    "\n",
    "params = chrom_to_params(chrom, params_template)\n",
    "\n",
    "# for key in params:\n",
    "#     print(params_ori[key] - params[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fitness(model, params):\n",
    "    model.load_state_dict(params)\n",
    "    loss = train(model, x_tensor, y_tensor, num_epoches=100, batch_size=8192, learning_rate=1e-3)\n",
    "    fitness = 1 / loss\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "for key in params_template:\n",
    "    num_params += np.prod(params_template[key].shape)\n",
    "genome = np.zeros((pop_size, num_params))\n",
    "fitness_array = np.zeros(pop_size)\n",
    "\n",
    "# 初始化种群，并计算相应的适应度\n",
    "for i in range(pop_size):\n",
    "    reset_model(model)\n",
    "    params = copy.deepcopy(model.state_dict())\n",
    "    fitness = compute_fitness(model, params)\n",
    "    chrom = params_to_chrom(params)\n",
    "    genome[i] = chrom\n",
    "    fitness_array[i] = fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看一下最好的\n",
    "best_index = np.argmax(fitness_array)\n",
    "best_chrom = genome[best_index]\n",
    "best_fitness = fitness_array[best_index]\n",
    "avg_fitness = np.mean(fitness_array)\n",
    "trace = (avg_fitness, best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(genome, fitness_array, pop_size):\n",
    "    indices = np.random.choice(np.arange(pop_size), size=pop_size, p=fitness_array/fitness_array.sum())\n",
    "    return genome[indices], fitness_array[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross(genome, idx, pop_size, num_params, cross_prob=0.8):\n",
    "    if np.random.rand() < cross_prob:\n",
    "        idx_other = np.random.choice(np.delete(np.arange(pop_size), idx), size=1)\n",
    "        cross_rate = np.random.rand()\n",
    "        cross_points = np.random.random(num_params) < 0.5\n",
    "        genome[idx, cross_points], genome[idx_other, cross_points] = \\\n",
    "            (1-cross_prob) * genome[idx, cross_points] + cross_prob * genome[idx_other, cross_points], \\\n",
    "            (1-cross_prob) * genome[idx_other, cross_points] + cross_prob * genome[idx, cross_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(genome, idx, pop_size, num_params, mutate_prob=0.03):\n",
    "    mutate_points = np.random.random(num_params) < mutate_prob\n",
    "    mutate_mea = np.random.randn(num_params) * np.std(genome, axis=0) + np.mean(genome, axis=0)\n",
    "    genome[idx] += mutate_points * mutate_mea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(maxgen):\n",
    "    # 选择\n",
    "    genome, fitness_array = select(genome, fitness_array, pop_size)\n",
    "    for idx in range(pop_size):\n",
    "        # 交叉\n",
    "        cross(genome, idx, pop_size, num_params)\n",
    "        # 变异\n",
    "        # mutate(genome, idx, pop_size, num_params)\n",
    "    for idx in range(pop_size):\n",
    "        # 更新适应度\n",
    "        fitness_array[idx] = compute_fitness(model, chrom_to_params(genome[idx], params_template))\n",
    "    print(genome)\n",
    "    print(fitness_array)\n",
    "    print(fitness_array.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(genome, axis=0).shape\n",
    "np.std(genome, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = chrom_to_params(genome[np.argmax(fitness_array)], params_template)\n",
    "model.load_state_dict(params)\n",
    "train(model, x_tensor, y_tensor, num_epoches=100, batch_size=4096, learning_rate=1e-3)\n",
    "plot_model(model, x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}